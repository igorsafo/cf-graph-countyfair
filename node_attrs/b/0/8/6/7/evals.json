{
 "archived": false,
 "branch": "main",
 "conda-forge.yml": {
  "bot": {
   "inspection": "update-grayskull"
  },
  "conda_build": {
   "error_overlinking": true
  },
  "conda_forge_output_validation": true,
  "github": {
   "branch_name": "main",
   "tooling_branch_name": "main"
  }
 },
 "feedstock_name": "evals",
 "hash_type": "sha256",
 "linux_64_meta_yaml": {
  "about": {
   "home": "https://github.com/openai/evals",
   "license": "MIT",
   "license_file": "LICENSE",
   "summary": "Evals is a framework for evaluating OpenAI models and an open-source registry of benchmarks."
  },
  "build": {
   "entry_points": [
    "oaieval = evals.cli.oaieval:main",
    "oaievalset = evals.cli.oaievalset:main"
   ],
   "noarch": "python",
   "number": "0",
   "script": "PYTHON -m pip install . -vv"
  },
  "extra": {
   "recipe-maintainers": [
    "BastianZim"
   ]
  },
  "package": {
   "name": "evals",
   "version": "1.0.3.post1"
  },
  "requirements": {
   "host": [
    "python >=3.9",
    "pip"
   ],
   "run": [
    "python >=3.9",
    "mypy",
    "openai >=0.27.2",
    "tiktoken",
    "blobfile",
    "backoff",
    "numpy",
    "snowflake-connector-python",
    "pandas",
    "fire",
    "pydantic",
    "tqdm",
    "nltk",
    "filelock",
    "mock",
    "langdetect",
    "termcolor",
    "lz4",
    "pyzstd",
    "pyyaml",
    "sacrebleu",
    "matplotlib-base",
    "setuptools-scm"
   ]
  },
  "source": {
   "sha256": "d24f525e0051d48662f38f4f1216d61ea0079df5a5ec0ee5582c28b7eeed4661",
   "url": "https://pypi.io/packages/source/e/evals/evals-1.0.3.post1.tar.gz"
  },
  "test": {
   "commands": [
    "pip check",
    "oaieval --help",
    "oaievalset --help"
   ],
   "imports": [
    "evals"
   ],
   "requires": [
    "pip"
   ]
  }
 },
 "linux_64_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "backoff",
    "blobfile",
    "filelock",
    "fire",
    "langdetect",
    "lz4",
    "matplotlib-base",
    "mock",
    "mypy",
    "nltk",
    "numpy",
    "openai",
    "pandas",
    "pydantic",
    "python",
    "pyyaml",
    "pyzstd",
    "sacrebleu",
    "setuptools-scm",
    "snowflake-connector-python",
    "termcolor",
    "tiktoken",
    "tqdm"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "meta_yaml": {
  "about": {
   "home": "https://github.com/openai/evals",
   "license": "MIT",
   "license_file": "LICENSE",
   "summary": "Evals is a framework for evaluating OpenAI models and an open-source registry of benchmarks."
  },
  "build": {
   "entry_points": [
    "oaieval = evals.cli.oaieval:main",
    "oaievalset = evals.cli.oaievalset:main"
   ],
   "noarch": "python",
   "number": "0",
   "script": "PYTHON -m pip install . -vv"
  },
  "extra": {
   "recipe-maintainers": [
    "BastianZim"
   ]
  },
  "package": {
   "name": "evals",
   "version": "1.0.3.post1"
  },
  "requirements": {
   "host": [
    "python >=3.9",
    "pip"
   ],
   "run": [
    "python >=3.9",
    "mypy",
    "openai >=0.27.2",
    "tiktoken",
    "blobfile",
    "backoff",
    "numpy",
    "snowflake-connector-python",
    "pandas",
    "fire",
    "pydantic",
    "tqdm",
    "nltk",
    "filelock",
    "mock",
    "langdetect",
    "termcolor",
    "lz4",
    "pyzstd",
    "pyyaml",
    "sacrebleu",
    "matplotlib-base",
    "setuptools-scm"
   ]
  },
  "source": {
   "sha256": "d24f525e0051d48662f38f4f1216d61ea0079df5a5ec0ee5582c28b7eeed4661",
   "url": "https://pypi.io/packages/source/e/evals/evals-1.0.3.post1.tar.gz"
  },
  "test": {
   "commands": [
    "pip check",
    "oaieval --help",
    "oaievalset --help"
   ],
   "imports": [
    "evals"
   ],
   "requires": [
    "pip"
   ]
  }
 },
 "name": "evals",
 "outputs_names": {
  "__set__": true,
  "elements": [
   "evals"
  ]
 },
 "parsing_error": false,
 "platforms": [
  "linux_64"
 ],
 "pr_info": {
  "__lazy_json__": "pr_info/evals.json"
 },
 "raw_meta_yaml": "{% set name = \"evals\" %}\n{% set version = \"1.0.3.post1\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/evals-{{ version }}.tar.gz\n  sha256: d24f525e0051d48662f38f4f1216d61ea0079df5a5ec0ee5582c28b7eeed4661\n\nbuild:\n  entry_points:\n    - oaieval = evals.cli.oaieval:main\n    - oaievalset = evals.cli.oaievalset:main\n  noarch: python\n  script: {{ PYTHON }} -m pip install . -vv\n  number: 0\n\nrequirements:\n  host:\n    - python >=3.9\n    - pip\n  run:\n    - python >=3.9\n    - mypy\n    - openai >=0.27.2\n    - tiktoken\n    - blobfile\n    - backoff\n    - numpy\n    - snowflake-connector-python\n    - pandas\n    - fire\n    - pydantic\n    - tqdm\n    - nltk\n    - filelock\n    - mock\n    - langdetect\n    - termcolor\n    - lz4\n    - pyzstd\n    - pyyaml\n    - sacrebleu\n    - matplotlib-base\n    - setuptools-scm\n\ntest:\n  imports:\n    - evals\n  commands:\n    - pip check\n    - oaieval --help\n    - oaievalset --help\n  requires:\n    - pip\n\nabout:\n  home: https://github.com/openai/evals\n  summary: Evals is a framework for evaluating OpenAI models and an open-source registry of benchmarks.\n  license: MIT\n  license_file: LICENSE\n\nextra:\n  recipe-maintainers:\n    - BastianZim\n",
 "req": {
  "__set__": true,
  "elements": [
   "backoff",
   "blobfile",
   "filelock",
   "fire",
   "langdetect",
   "lz4",
   "matplotlib-base",
   "mock",
   "mypy",
   "nltk",
   "numpy",
   "openai",
   "pandas",
   "pip",
   "pydantic",
   "python",
   "pyyaml",
   "pyzstd",
   "sacrebleu",
   "setuptools-scm",
   "snowflake-connector-python",
   "termcolor",
   "tiktoken",
   "tqdm"
  ]
 },
 "requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "backoff",
    "blobfile",
    "filelock",
    "fire",
    "langdetect",
    "lz4",
    "matplotlib-base",
    "mock",
    "mypy",
    "nltk",
    "numpy",
    "openai",
    "pandas",
    "pydantic",
    "python",
    "pyyaml",
    "pyzstd",
    "sacrebleu",
    "setuptools-scm",
    "snowflake-connector-python",
    "termcolor",
    "tiktoken",
    "tqdm"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "strong_exports": false,
 "total_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "python >=3.9"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "backoff",
    "blobfile",
    "filelock",
    "fire",
    "langdetect",
    "lz4",
    "matplotlib-base",
    "mock",
    "mypy",
    "nltk",
    "numpy",
    "openai >=0.27.2",
    "pandas",
    "pydantic",
    "python >=3.9",
    "pyyaml",
    "pyzstd",
    "sacrebleu",
    "setuptools-scm",
    "snowflake-connector-python",
    "termcolor",
    "tiktoken",
    "tqdm"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "url": "https://pypi.io/packages/source/e/evals/evals-1.0.3.post1.tar.gz",
 "version": "1.0.3.post1",
 "version_pr_info": {
  "__lazy_json__": "version_pr_info/evals.json"
 }
}