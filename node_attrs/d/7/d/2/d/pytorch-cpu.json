{
 "archived": false,
 "branch": "main",
 "conda-forge.yml": {
  "azure": {
   "free_disk_space": true,
   "settings_linux": {
    "timeoutInMinutes": 1
   },
   "settings_osx": {
    "pool": {
     "vmImage": "macos-12"
    }
   }
  },
  "build_platform": {
   "linux_aarch64": "linux_64",
   "osx_arm64": "osx_64"
  },
  "conda_build": {
   "pkg_format": "2"
  },
  "conda_forge_output_validation": true,
  "github": {
   "branch_name": "main",
   "tooling_branch_name": "main"
  },
  "os_version": {
   "linux_64": "cos7"
  },
  "provider": {
   "linux_aarch64": "azure"
  },
  "remote_ci_setup": [
   "py-lief=0.12.3",
   "conda-forge-ci-setup=3"
  ],
  "test_on_native_only": true
 },
 "feedstock_name": "pytorch-cpu",
 "linux_64_meta_yaml": {
  "about": {
   "home": "https://pytorch.org/",
   "license": "BSD-3-Clause",
   "license_family": "BSD",
   "license_file": [
    "LICENSE",
    "NOTICE",
    "third_party/pybind11/LICENSE",
    "LICENSE",
    "NOTICE",
    "third_party/pybind11/LICENSE",
    "LICENSE",
    "NOTICE",
    "third_party/pybind11/LICENSE",
    "LICENSE",
    "NOTICE",
    "third_party/pybind11/LICENSE",
    "LICENSE",
    "NOTICE",
    "third_party/pybind11/LICENSE"
   ],
   "summary": "PyTorch is an optimized tensor library for deep learning using GPUs and CPUs."
  },
  "build": {
   "number": "201",
   "skip": true
  },
  "extra": {
   "feedstock-name": "pytorch-cpu",
   "recipe-maintainers": [
    "hmaarrfk",
    "sodre",
    "benjaminrwilson",
    "Tobias-Fischer",
    "beckermr",
    "hmaarrfk",
    "sodre",
    "benjaminrwilson",
    "Tobias-Fischer",
    "beckermr",
    "hmaarrfk",
    "sodre",
    "benjaminrwilson",
    "Tobias-Fischer",
    "beckermr",
    "hmaarrfk",
    "sodre",
    "benjaminrwilson",
    "Tobias-Fischer",
    "beckermr",
    "hmaarrfk",
    "sodre",
    "benjaminrwilson",
    "Tobias-Fischer",
    "beckermr"
   ]
  },
  "outputs": [
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "run_exports": [
      "pytorch"
     ],
     "string": "cuda120py310h1234567_201"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "sysroot_linux-64  2.17",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "patch",
      "git",
      "libgomp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "make"
     ],
     "host": [
      "cudnn",
      "nccl",
      "magma",
      "cuda-version 12.0",
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "future",
      "six",
      "libcblas",
      "liblapack",
      "libgomp",
      "libprotobuf",
      "sleef",
      "typing",
      "libuv",
      "pkg-config",
      "typing_extensions"
     ],
     "run": [
      "cudnn",
      "magma",
      "python",
      "typing_extensions",
      "sympy",
      "filelock",
      "jinja2",
      "networkx",
      "nomkl",
      "fsspec",
      "__cuda"
     ],
     "run_constrained": [
      "pytorch-gpu ==2.1.0",
      "pytorch-cpu ==99999999"
     ]
    },
    "script": "build_pytorch.sh",
    "test": {
     "commands": [
      "OMP_NUM_THREADS=4 python ./test/run_test.py || true",
      "pip check",
      "python -c \"import torch; print(torch.__version__)\""
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "mock",
      "pip",
      "expecttest",
      "xmlrunner"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cuda120py310h1234567_201",
     "track_features": null
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "run_exports": [
      "pytorch"
     ],
     "string": "cuda120py38h1234567_201"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "sysroot_linux-64  2.17",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "patch",
      "git",
      "libgomp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "make"
     ],
     "host": [
      "cudnn",
      "nccl",
      "magma",
      "cuda-version 12.0",
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "future",
      "six",
      "libcblas",
      "liblapack",
      "libgomp",
      "libprotobuf",
      "sleef",
      "typing",
      "libuv",
      "pkg-config",
      "typing_extensions"
     ],
     "run": [
      "cudnn",
      "magma",
      "python",
      "typing_extensions",
      "sympy",
      "filelock",
      "jinja2",
      "networkx",
      "nomkl",
      "fsspec",
      "__cuda"
     ],
     "run_constrained": [
      "pytorch-gpu ==2.1.0",
      "pytorch-cpu ==99999999"
     ]
    },
    "script": "build_pytorch.sh",
    "test": {
     "commands": [
      "OMP_NUM_THREADS=4 python ./test/run_test.py || true",
      "pip check",
      "python -c \"import torch; print(torch.__version__)\""
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "mock",
      "pip",
      "expecttest",
      "xmlrunner"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cuda120py38h1234567_201",
     "track_features": null
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "run_exports": [
      "pytorch"
     ],
     "string": "cuda120py39h1234567_201"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "sysroot_linux-64  2.17",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "patch",
      "git",
      "libgomp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "make"
     ],
     "host": [
      "cudnn",
      "nccl",
      "magma",
      "cuda-version 12.0",
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "future",
      "six",
      "libcblas",
      "liblapack",
      "libgomp",
      "libprotobuf",
      "sleef",
      "typing",
      "libuv",
      "pkg-config",
      "typing_extensions"
     ],
     "run": [
      "cudnn",
      "magma",
      "python",
      "typing_extensions",
      "sympy",
      "filelock",
      "jinja2",
      "networkx",
      "nomkl",
      "fsspec",
      "__cuda"
     ],
     "run_constrained": [
      "pytorch-gpu ==2.1.0",
      "pytorch-cpu ==99999999"
     ]
    },
    "script": "build_pytorch.sh",
    "test": {
     "commands": [
      "OMP_NUM_THREADS=4 python ./test/run_test.py || true",
      "pip check",
      "python -c \"import torch; print(torch.__version__)\""
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "mock",
      "pip",
      "expecttest",
      "xmlrunner"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cuda120py39h1234567_201",
     "track_features": null
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "run_exports": [
      "pytorch"
     ],
     "string": "cuda120py311h1234567_201"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "sysroot_linux-64  2.17",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "patch",
      "git",
      "libgomp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "make"
     ],
     "host": [
      "cudnn",
      "nccl",
      "magma",
      "cuda-version 12.0",
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "future",
      "six",
      "libcblas",
      "liblapack",
      "libgomp",
      "libprotobuf",
      "sleef",
      "typing",
      "libuv",
      "pkg-config",
      "typing_extensions"
     ],
     "run": [
      "cudnn",
      "magma",
      "python",
      "typing_extensions",
      "sympy",
      "filelock",
      "jinja2",
      "networkx",
      "nomkl",
      "fsspec",
      "__cuda"
     ],
     "run_constrained": [
      "pytorch-gpu ==2.1.0",
      "pytorch-cpu ==99999999"
     ]
    },
    "script": "build_pytorch.sh",
    "test": {
     "commands": [
      "OMP_NUM_THREADS=4 python ./test/run_test.py || true",
      "pip check",
      "python -c \"import torch; print(torch.__version__)\""
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "mock",
      "pip",
      "expecttest",
      "xmlrunner"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cuda120py311h1234567_201",
     "track_features": null
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "run_exports": [
      "pytorch"
     ],
     "string": "cuda120py312h1234567_201"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "sysroot_linux-64  2.17",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "patch",
      "git",
      "libgomp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "make"
     ],
     "host": [
      "cudnn",
      "nccl",
      "magma",
      "cuda-version 12.0",
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "future",
      "six",
      "libcblas",
      "liblapack",
      "libgomp",
      "libprotobuf",
      "sleef",
      "typing",
      "libuv",
      "pkg-config",
      "typing_extensions"
     ],
     "run": [
      "cudnn",
      "magma",
      "python",
      "typing_extensions",
      "sympy",
      "filelock",
      "jinja2",
      "networkx",
      "nomkl",
      "fsspec",
      "__cuda"
     ],
     "run_constrained": [
      "pytorch-gpu ==2.1.0",
      "pytorch-cpu ==99999999"
     ]
    },
    "script": "build_pytorch.sh",
    "test": {
     "commands": [
      "OMP_NUM_THREADS=4 python ./test/run_test.py || true",
      "pip check",
      "python -c \"import torch; print(torch.__version__)\""
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "mock",
      "pip",
      "expecttest",
      "xmlrunner"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cuda120py312h1234567_201",
     "track_features": null
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   }
  ],
  "package": {
   "name": "pytorch-recipe",
   "version": "2.1.0"
  },
  "source": {
   "git_rev": "v2.1.0",
   "git_url": "https://github.com/pytorch/pytorch.git",
   "patches": [
    "patches/0001-Allow-splayed-layouts.patch",
    "patches/nvtoolsext.patch",
    "patches/0001-Allow-splayed-layouts.patch",
    "patches/nvtoolsext.patch",
    "patches/0001-Allow-splayed-layouts.patch",
    "patches/nvtoolsext.patch",
    "patches/0001-Allow-splayed-layouts.patch",
    "patches/nvtoolsext.patch",
    "patches/0001-Allow-splayed-layouts.patch",
    "patches/nvtoolsext.patch"
   ]
  }
 },
 "linux_64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cmake",
    "cuda_compiler_stub",
    "cxx_compiler_stub",
    "git",
    "libgomp",
    "libprotobuf",
    "make",
    "ninja",
    "patch",
    "protobuf",
    "sysroot_linux-64"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "cuda-version",
    "cudnn",
    "future",
    "libcblas",
    "libgomp",
    "liblapack",
    "libprotobuf",
    "libuv",
    "magma",
    "nccl",
    "numpy",
    "pip",
    "pkg-config",
    "python",
    "pyyaml",
    "requests",
    "setuptools",
    "six",
    "sleef",
    "typing",
    "typing_extensions"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "__cuda",
    "cudnn",
    "filelock",
    "fsspec",
    "jinja2",
    "magma",
    "networkx",
    "nomkl",
    "python",
    "pytorch",
    "sympy",
    "typing_extensions"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cxx_compiler_stub",
    "expecttest",
    "hypothesis",
    "mock",
    "pip",
    "pydot",
    "pytest",
    "tabulate",
    "xmlrunner"
   ]
  }
 },
 "meta_yaml": {
  "about": {
   "home": "https://pytorch.org/",
   "license": "BSD-3-Clause",
   "license_family": "BSD",
   "license_file": [
    "LICENSE",
    "NOTICE",
    "third_party/pybind11/LICENSE",
    "LICENSE",
    "NOTICE",
    "third_party/pybind11/LICENSE",
    "LICENSE",
    "NOTICE",
    "third_party/pybind11/LICENSE",
    "LICENSE",
    "NOTICE",
    "third_party/pybind11/LICENSE",
    "LICENSE",
    "NOTICE",
    "third_party/pybind11/LICENSE"
   ],
   "summary": "PyTorch is an optimized tensor library for deep learning using GPUs and CPUs."
  },
  "build": {
   "number": "201",
   "skip": true
  },
  "extra": {
   "feedstock-name": "pytorch-cpu",
   "recipe-maintainers": [
    "hmaarrfk",
    "sodre",
    "benjaminrwilson",
    "Tobias-Fischer",
    "beckermr",
    "hmaarrfk",
    "sodre",
    "benjaminrwilson",
    "Tobias-Fischer",
    "beckermr",
    "hmaarrfk",
    "sodre",
    "benjaminrwilson",
    "Tobias-Fischer",
    "beckermr",
    "hmaarrfk",
    "sodre",
    "benjaminrwilson",
    "Tobias-Fischer",
    "beckermr",
    "hmaarrfk",
    "sodre",
    "benjaminrwilson",
    "Tobias-Fischer",
    "beckermr"
   ]
  },
  "outputs": [
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "run_exports": [
      "pytorch"
     ],
     "string": "cuda120py310h1234567_201"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "sysroot_linux-64  2.17",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "patch",
      "git",
      "libgomp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "make"
     ],
     "host": [
      "cudnn",
      "nccl",
      "magma",
      "cuda-version 12.0",
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "future",
      "six",
      "libcblas",
      "liblapack",
      "libgomp",
      "libprotobuf",
      "sleef",
      "typing",
      "libuv",
      "pkg-config",
      "typing_extensions"
     ],
     "run": [
      "cudnn",
      "magma",
      "python",
      "typing_extensions",
      "sympy",
      "filelock",
      "jinja2",
      "networkx",
      "nomkl",
      "fsspec",
      "__cuda"
     ],
     "run_constrained": [
      "pytorch-gpu ==2.1.0",
      "pytorch-cpu ==99999999"
     ]
    },
    "script": "build_pytorch.sh",
    "test": {
     "commands": [
      "OMP_NUM_THREADS=4 python ./test/run_test.py || true",
      "pip check",
      "python -c \"import torch; print(torch.__version__)\""
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "mock",
      "pip",
      "expecttest",
      "xmlrunner"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cuda120py310h1234567_201",
     "track_features": null
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "run_exports": [
      "pytorch"
     ],
     "string": "cuda120py38h1234567_201"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "sysroot_linux-64  2.17",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "patch",
      "git",
      "libgomp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "make"
     ],
     "host": [
      "cudnn",
      "nccl",
      "magma",
      "cuda-version 12.0",
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "future",
      "six",
      "libcblas",
      "liblapack",
      "libgomp",
      "libprotobuf",
      "sleef",
      "typing",
      "libuv",
      "pkg-config",
      "typing_extensions"
     ],
     "run": [
      "cudnn",
      "magma",
      "python",
      "typing_extensions",
      "sympy",
      "filelock",
      "jinja2",
      "networkx",
      "nomkl",
      "fsspec",
      "__cuda"
     ],
     "run_constrained": [
      "pytorch-gpu ==2.1.0",
      "pytorch-cpu ==99999999"
     ]
    },
    "script": "build_pytorch.sh",
    "test": {
     "commands": [
      "OMP_NUM_THREADS=4 python ./test/run_test.py || true",
      "pip check",
      "python -c \"import torch; print(torch.__version__)\""
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "mock",
      "pip",
      "expecttest",
      "xmlrunner"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cuda120py38h1234567_201",
     "track_features": null
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "run_exports": [
      "pytorch"
     ],
     "string": "cuda120py39h1234567_201"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "sysroot_linux-64  2.17",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "patch",
      "git",
      "libgomp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "make"
     ],
     "host": [
      "cudnn",
      "nccl",
      "magma",
      "cuda-version 12.0",
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "future",
      "six",
      "libcblas",
      "liblapack",
      "libgomp",
      "libprotobuf",
      "sleef",
      "typing",
      "libuv",
      "pkg-config",
      "typing_extensions"
     ],
     "run": [
      "cudnn",
      "magma",
      "python",
      "typing_extensions",
      "sympy",
      "filelock",
      "jinja2",
      "networkx",
      "nomkl",
      "fsspec",
      "__cuda"
     ],
     "run_constrained": [
      "pytorch-gpu ==2.1.0",
      "pytorch-cpu ==99999999"
     ]
    },
    "script": "build_pytorch.sh",
    "test": {
     "commands": [
      "OMP_NUM_THREADS=4 python ./test/run_test.py || true",
      "pip check",
      "python -c \"import torch; print(torch.__version__)\""
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "mock",
      "pip",
      "expecttest",
      "xmlrunner"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cuda120py39h1234567_201",
     "track_features": null
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "run_exports": [
      "pytorch"
     ],
     "string": "cuda120py311h1234567_201"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "sysroot_linux-64  2.17",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "patch",
      "git",
      "libgomp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "make"
     ],
     "host": [
      "cudnn",
      "nccl",
      "magma",
      "cuda-version 12.0",
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "future",
      "six",
      "libcblas",
      "liblapack",
      "libgomp",
      "libprotobuf",
      "sleef",
      "typing",
      "libuv",
      "pkg-config",
      "typing_extensions"
     ],
     "run": [
      "cudnn",
      "magma",
      "python",
      "typing_extensions",
      "sympy",
      "filelock",
      "jinja2",
      "networkx",
      "nomkl",
      "fsspec",
      "__cuda"
     ],
     "run_constrained": [
      "pytorch-gpu ==2.1.0",
      "pytorch-cpu ==99999999"
     ]
    },
    "script": "build_pytorch.sh",
    "test": {
     "commands": [
      "OMP_NUM_THREADS=4 python ./test/run_test.py || true",
      "pip check",
      "python -c \"import torch; print(torch.__version__)\""
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "mock",
      "pip",
      "expecttest",
      "xmlrunner"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cuda120py311h1234567_201",
     "track_features": null
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "run_exports": [
      "pytorch"
     ],
     "string": "cuda120py312h1234567_201"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "sysroot_linux-64  2.17",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "patch",
      "git",
      "libgomp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "make"
     ],
     "host": [
      "cudnn",
      "nccl",
      "magma",
      "cuda-version 12.0",
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "future",
      "six",
      "libcblas",
      "liblapack",
      "libgomp",
      "libprotobuf",
      "sleef",
      "typing",
      "libuv",
      "pkg-config",
      "typing_extensions"
     ],
     "run": [
      "cudnn",
      "magma",
      "python",
      "typing_extensions",
      "sympy",
      "filelock",
      "jinja2",
      "networkx",
      "nomkl",
      "fsspec",
      "__cuda"
     ],
     "run_constrained": [
      "pytorch-gpu ==2.1.0",
      "pytorch-cpu ==99999999"
     ]
    },
    "script": "build_pytorch.sh",
    "test": {
     "commands": [
      "OMP_NUM_THREADS=4 python ./test/run_test.py || true",
      "pip check",
      "python -c \"import torch; print(torch.__version__)\""
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "mock",
      "pip",
      "expecttest",
      "xmlrunner"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cuda120py312h1234567_201",
     "track_features": null
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   }
  ],
  "package": {
   "name": "pytorch-recipe",
   "version": "2.1.0"
  },
  "source": {
   "git_rev": "v2.1.0",
   "git_url": "https://github.com/pytorch/pytorch.git",
   "patches": [
    "patches/0001-Allow-splayed-layouts.patch",
    "patches/nvtoolsext.patch",
    "patches/0001-Allow-splayed-layouts.patch",
    "patches/nvtoolsext.patch",
    "patches/0001-Allow-splayed-layouts.patch",
    "patches/nvtoolsext.patch",
    "patches/0001-Allow-splayed-layouts.patch",
    "patches/nvtoolsext.patch",
    "patches/0001-Allow-splayed-layouts.patch",
    "patches/nvtoolsext.patch"
   ]
  }
 },
 "name": "pytorch-recipe",
 "outputs_names": {
  "__set__": true,
  "elements": [
   "pytorch",
   "pytorch-gpu"
  ]
 },
 "parsing_error": false,
 "platforms": [
  "linux_64"
 ],
 "pr_info": {
  "__lazy_json__": "pr_info/pytorch-cpu.json"
 },
 "raw_meta_yaml": "# TODO: remmeber to remove skip cuda != 12.0 when the version or build number gets bumped\n{% set version = \"2.1.0\" %}\n# Build 1 was only ever built for cuda 12.0\n# Unskip other things when it passes\n{% set build = 1 %}\n\n{% if cuda_compiler_version != \"None\" %}\n{% set build = build + 200 %}\n{% endif %}\n\n{% if blas_impl == \"mkl\" %}\n{% set build = build + 100 %}\n{% endif %}\n\n{% if cuda_compiler_version in (None, \"None\", True, False) %}\n{% set cuda_major = 0 %}\n{% else %}\n{% set cuda_major = environ.get(\"cuda_compiler_version\", \"11.8\").split(\".\")[0] | int %}\n{% endif %}\n\npackage:\n  name: pytorch-recipe\n  version: {{ version }}\n\nsource:\n  # for local testing use a tarball including submodules\n  git_url: https://github.com/pytorch/pytorch.git\n  git_tag: v{{ version }}\n  patches:\n    - patches/nvml.patch  # [cuda_compiler_version == \"11.2\"]\n    # The patch below is probably OK for other versions too, but it is untested with them\n    # https://github.com/conda-forge/pytorch-cpu-feedstock/pull/203#issuecomment-1797352452\n    # https://github.com/pytorch/pytorch/pull/82695/files#diff-8e5cb190cc46be808993381a31fe9c027705d356b6bc0460368c0310ae82b273R61-R66\n    # https://github.com/pytorch/pytorch/pull/108932\n    - patches/0001-Allow-splayed-layouts.patch  # [cuda_compiler_version == \"12.0\"]\n    # https://github.com/pytorch/pytorch/issues/101135\n    # the following patch was transcribed to work wit 2.1.0\n    # https://gist.github.com/andreigh/f78f631e0039f0af410b269acbb0c8dc\n    - patches/nvtoolsext.patch                  # [cuda_compiler_version == \"12.0\"]\n\nbuild:\n  number: {{ build }}\n  skip: true  # [win]\n  skip: true  # [cuda_compiler_version != \"None\" and blas_impl != \"mkl\"]\n  skip: true  # [cuda_compiler_version == \"10.2\"]\n  skip: true  # [cuda_compiler_version == \"11.0\"]\n  skip: true  # [cuda_compiler_version == \"11.1\"]\n  # TODO: remove this skip when enabling the next build\n  skip: true  # [cuda_compiler_version != \"12.0\"]\n\noutputs:\n  - name: pytorch\n    build:\n      string: cuda{{ cuda_compiler_version | replace('.', '') }}py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != \"None\"]\n      string: cpu_{{ blas_impl }}_py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}                                                # [cuda_compiler_version == \"None\"]\n      detect_binary_files_with_prefix: false\n      run_exports:\n        - {{ pin_subpackage('pytorch', max_pin='x.x') }}\n    script: build_pytorch.sh  # [not win]\n    script: bld_pytorch.bat   # [win]\n    requirements:\n      build:\n        - python                                 # [build_platform != target_platform]\n        - cross-python_{{ target_platform }}     # [build_platform != target_platform]\n        - numpy                                  # [build_platform != target_platform]\n        - sysroot_linux-64  2.17  # [linux64]\n        - {{ compiler('c') }}\n        - {{ compiler('cxx') }}\n        - {{ compiler('cuda') }}    # [cuda_compiler_version != \"None\"]\n        {% if cuda_major >= 12 %}\n        - cuda-driver-dev                        # [build_platform != target_platform]\n        - cuda-cudart-dev                        # [build_platform != target_platform]\n        - cuda-nvrtc-dev                         # [build_platform != target_platform]\n        - cuda-nvtx-dev                          # [build_platform != target_platform]\n        - cuda-nvml-dev                          # [build_platform != target_platform]\n        - cuda-profiler-api                      # [build_platform != target_platform]\n        - libcublas-dev                          # [build_platform != target_platform]\n        - libcufft-dev                           # [build_platform != target_platform]\n        - libcurand-dev                          # [build_platform != target_platform]\n        - libcusolver-dev                        # [build_platform != target_platform]\n        - libcusparse-dev                        # [build_platform != target_platform]\n        {% endif %}\n        # Dec 2020: it seems that git is broken on windows, so we use m2-git\n        - patch     # [not win]\n        - m2-patch  # [win]\n        - git       # [not win]\n        - m2-git    # [win]\n        - libgomp   # [linux]\n        - llvm-openmp    # [osx]\n        - cmake\n        - ninja\n        # Keep libprotobuf here so that a compatibile version\n        # of protobuf is installed between build and host\n        - libprotobuf\n        - protobuf\n        - make      # [linux]\n      host:\n        # GPU requirements\n        - cudnn                           # [cuda_compiler_version != \"None\"]\n        - nccl                            # [cuda_compiler_version != \"None\"]\n        - magma                           # [cuda_compiler_version != \"None\"]\n        - cuda-version {{ cuda_compiler_version }}  # [cuda_compiler_version != \"None\"]\n        {% if cuda_major >= 12 %}\n        - cuda-driver-dev\n        - cuda-cudart-dev\n        - cuda-nvrtc-dev\n        - cuda-nvtx-dev\n        - cuda-nvml-dev\n        - cuda-profiler-api\n        - libcublas-dev\n        - libcufft-dev\n        - libcurand-dev\n        - libcusolver-dev\n        - libcusparse-dev\n        {% endif %}\n        # other requirements\n        - python\n        - numpy\n        - pip\n        - setuptools\n        - pyyaml\n        - requests\n        - future\n        - six\n        - mkl-devel {{ mkl }}   # [blas_impl == \"mkl\"]\n        - libcblas * *_mkl      # [blas_impl == \"mkl\"]\n        - libcblas              # [blas_impl != \"mkl\"]\n        - liblapack             # [blas_impl != \"mkl\"]\n        - libgomp   # [linux]\n        - llvm-openmp    # [osx]\n        - libprotobuf\n        - sleef\n        - typing\n        - libuv\n        - pkg-config  # [unix]\n        - typing_extensions\n      run:\n        - llvm-openmp    # [osx]\n        # GPU requirements without run_exports\n        - {{ pin_compatible('cudnn') }}                       # [cuda_compiler_version != \"None\"]\n        - {{ pin_compatible('magma', max_pin='x.x.x') }}      # [cuda_compiler_version != \"None\"]\n        # other requirements\n        - python\n        - typing_extensions\n        - sympy\n        - filelock\n        - jinja2\n        - networkx\n        - nomkl                 # [blas_impl != \"mkl\"]\n        - fsspec\n        # avoid that people without GPUs needlessly download ~0.5-1GB\n        - __cuda  # [cuda_compiler_version != \"None\"]\n      run_constrained:\n        # These constraints ensure conflict between pytorch and\n        # pytorch-cpu 1.1 which we built before conda-forge had GPU infrastructure\n        # built into place.\n        # https://github.com/conda-forge/pytorch-cpu-feedstock/issues/65\n        - pytorch-cpu =={{ version }}  # [cuda_compiler_version == \"None\"]\n        - pytorch-gpu ==99999999       # [cuda_compiler_version == \"None\"]\n        - pytorch-gpu =={{ version }}  # [cuda_compiler_version != \"None\"]\n        - pytorch-cpu ==99999999       # [cuda_compiler_version != \"None\"]\n\n    test:\n      requires:\n        - {{ compiler('c') }}\n        - {{ compiler('cxx') }}\n        - hypothesis\n        - pytest\n        - tabulate\n        - pydot\n        - mock  # [linux]\n        - pip\n        - expecttest\n        - xmlrunner\n      imports:\n        - torch\n      source_files:\n        - test\n        # tools/ is needed to optimise test run\n        # as of pytorch=2.0.0, there is a bug when trying to run tests without the tools\n        - tools\n      commands:\n        - OMP_NUM_THREADS=4 python ./test/run_test.py || true  # [not win]\n        - python ./test/run_test.py  # [win]\n        # Run pip check so as to ensure that all pytorch packages are installed\n        # https://github.com/conda-forge/pytorch-cpu-feedstock/issues/24\n        - pip check\n        - python -c \"import torch; print(torch.__version__)\"\n        - python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"  # [x86 and cuda_compiler_version == \"None\"]\n        # At conda-forge, we target versions of OSX that are too old for MPS support\n        # But if users install a newer version of OSX, they will have MPS support\n        # https://github.com/conda-forge/pytorch-cpu-feedstock/pull/123#issuecomment-1186355073\n        # - python -c \"import torch; assert torch.backends.mps.is_available()\" # [osx]\n\n  # 2021/08/01, hmaarrfk\n  # While this seems like a roundabout way of defining the package name\n  # It helps the linter avoid errors on a package not having tests.\n  {% set pytorch_cpu_gpu = \"pytorch-cpu\" %}   # [cuda_compiler_version == \"None\"]\n  {% set pytorch_cpu_gpu = \"pytorch-gpu\" %}   # [cuda_compiler_version != \"None\"]\n  - name: {{ pytorch_cpu_gpu }}\n    build:\n      string: cuda{{ cuda_compiler_version | replace('.', '') }}py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != \"None\"]\n      string: cpu_{{ blas_impl }}_py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}                                      # [cuda_compiler_version == \"None\"]\n      detect_binary_files_with_prefix: False\n      # weigh down cpu implementation and give cuda preference\n      track_features:\n        - pytorch-cpu                                      # [cuda_compiler_version == \"None\"]\n    requirements:\n      run:\n        - {{ pin_subpackage(\"pytorch\", exact=True) }}\n    test:\n      imports:\n        - torch\n\nabout:\n  home: https://pytorch.org/\n  license: BSD-3-Clause\n  license_family: BSD\n  license_file:\n    - LICENSE\n    - NOTICE\n    - third_party/pybind11/LICENSE\n  summary: PyTorch is an optimized tensor library for deep learning using GPUs and CPUs.\n\nextra:\n  recipe-maintainers:\n    - hmaarrfk\n    - sodre\n    - benjaminrwilson\n    - Tobias-Fischer\n    - beckermr\n  feedstock-name: pytorch-cpu\n",
 "req": {
  "__set__": true,
  "elements": [
   "__cuda",
   "c_compiler_stub",
   "cmake",
   "cuda-version",
   "cuda_compiler_stub",
   "cudnn",
   "cxx_compiler_stub",
   "filelock",
   "fsspec",
   "future",
   "git",
   "jinja2",
   "libcblas",
   "libgomp",
   "liblapack",
   "libprotobuf",
   "libuv",
   "magma",
   "make",
   "nccl",
   "networkx",
   "ninja",
   "nomkl",
   "numpy",
   "patch",
   "pip",
   "pkg-config",
   "protobuf",
   "python",
   "pytorch",
   "pyyaml",
   "requests",
   "setuptools",
   "six",
   "sleef",
   "sympy",
   "sysroot_linux-64",
   "typing",
   "typing_extensions"
  ]
 },
 "requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cmake",
    "cuda_compiler_stub",
    "cxx_compiler_stub",
    "git",
    "libgomp",
    "libprotobuf",
    "make",
    "ninja",
    "patch",
    "protobuf",
    "sysroot_linux-64"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "ctng-compilers",
    "cuda-version",
    "cuda_compiler_stub",
    "cudnn",
    "cxx_compiler_stub",
    "future",
    "libcblas",
    "libgomp",
    "liblapack",
    "libprotobuf",
    "libuv",
    "magma",
    "nccl",
    "numpy",
    "pip",
    "pkg-config",
    "python",
    "pyyaml",
    "requests",
    "setuptools",
    "six",
    "sleef",
    "typing",
    "typing_extensions"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "__cuda",
    "c_compiler_stub",
    "ctng-compilers",
    "cuda_compiler_stub",
    "cudnn",
    "cxx_compiler_stub",
    "filelock",
    "fsspec",
    "jinja2",
    "magma",
    "networkx",
    "nomkl",
    "python",
    "pytorch",
    "sympy",
    "typing_extensions"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cxx_compiler_stub",
    "expecttest",
    "hypothesis",
    "mock",
    "pip",
    "pydot",
    "pytest",
    "tabulate",
    "xmlrunner"
   ]
  }
 },
 "strong_exports": false,
 "time": 1568135301.1552057,
 "total_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cmake",
    "cuda_compiler_stub",
    "cxx_compiler_stub",
    "git",
    "libgomp",
    "libprotobuf",
    "make",
    "ninja",
    "patch",
    "protobuf",
    "sysroot_linux-64  2.17"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "cuda-version 12.0",
    "cudnn",
    "future",
    "libcblas",
    "libgomp",
    "liblapack",
    "libprotobuf",
    "libuv",
    "magma",
    "nccl",
    "numpy",
    "pip",
    "pkg-config",
    "python",
    "pyyaml",
    "requests",
    "setuptools",
    "six",
    "sleef",
    "typing",
    "typing_extensions"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "__cuda",
    "cudnn",
    "filelock",
    "fsspec",
    "jinja2",
    "magma",
    "networkx",
    "nomkl",
    "python",
    "pytorch",
    "sympy",
    "typing_extensions"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cxx_compiler_stub",
    "expecttest",
    "hypothesis",
    "mock",
    "pip",
    "pydot",
    "pytest",
    "tabulate",
    "xmlrunner"
   ]
  }
 },
 "url": null,
 "version": "2.1.0",
 "version_pr_info": {
  "__lazy_json__": "version_pr_info/pytorch-cpu.json"
 }
}