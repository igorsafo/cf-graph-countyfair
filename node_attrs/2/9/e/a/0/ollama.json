{
 "archived": false,
 "branch": "main",
 "conda-forge.yml": {
  "build_platform": {
   "osx_arm64": "osx_64"
  }
 },
 "feedstock_name": "ollama",
 "hash_type": "sha256",
 "linux_64_meta_yaml": {
  "about": {
   "dev_url": "https://github.com/jmorganca/ollama",
   "home": "https://ollama.ai",
   "license": "MIT",
   "license_family": "MIT",
   "license_file": [
    "LICENSE",
    "licenses/",
    "LICENSE",
    "licenses/",
    "LICENSE",
    "licenses/",
    "LICENSE",
    "licenses/"
   ],
   "summary": "Get up and running with Llama 2 and other large language models locally"
  },
  "build": {
   "ignore_run_exports_from": null,
   "number": "4",
   "script": [
    "git config --system user.email \"conda-forge@numfocus.org\"",
    "git config --system user.name \"Conda Forge\"",
    "git config --global init.defaultBranch main",
    "pushd llm/llama.cpp/ggml\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "pushd llm/llama.cpp/gguf\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "export GOFLAGS=\"'-ldflags=-X=github.com/jmorganca/ollama/version.Version=0.1.11 -X=github.com/jmorganca/ollama/server.mode=release'\"",
    "go generate ./...",
    "go install .",
    "go-licenses save --save_path licenses ./...",
    "git config --system user.email \"conda-forge@numfocus.org\"",
    "git config --system user.name \"Conda Forge\"",
    "git config --global init.defaultBranch main",
    "pushd llm/llama.cpp/ggml\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "pushd llm/llama.cpp/gguf\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "export GOFLAGS=\"'-ldflags=-X=github.com/jmorganca/ollama/version.Version=0.1.11 -X=github.com/jmorganca/ollama/server.mode=release'\"",
    "go generate ./...",
    "go install .",
    "go-licenses save --save_path licenses ./...",
    "git config --system user.email \"conda-forge@numfocus.org\"",
    "git config --system user.name \"Conda Forge\"",
    "git config --global init.defaultBranch main",
    "pushd llm/llama.cpp/ggml\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "pushd llm/llama.cpp/gguf\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "export GOFLAGS=\"'-ldflags=-X=github.com/jmorganca/ollama/version.Version=0.1.11 -X=github.com/jmorganca/ollama/server.mode=release'\"",
    "go generate ./...",
    "go install .",
    "go-licenses save --save_path licenses ./...",
    "git config --system user.email \"conda-forge@numfocus.org\"",
    "git config --system user.name \"Conda Forge\"",
    "git config --global init.defaultBranch main",
    "pushd llm/llama.cpp/ggml\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "pushd llm/llama.cpp/gguf\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "export GOFLAGS=\"'-ldflags=-X=github.com/jmorganca/ollama/version.Version=0.1.11 -X=github.com/jmorganca/ollama/server.mode=release'\"",
    "go generate ./...",
    "go install .",
    "go-licenses save --save_path licenses ./..."
   ],
   "string": "cpu_h1234567_4"
  },
  "extra": {
   "recipe-maintainers": [
    "sodre",
    "sodre",
    "sodre",
    "sodre"
   ]
  },
  "package": {
   "name": "ollama",
   "version": "0.1.11"
  },
  "requirements": {
   "build": [
    "c_compiler_stub",
    "cxx_compiler_stub",
    "cuda_compiler_stub",
    "go_compiler_stub 1.20",
    "go-licenses",
    "git",
    "cmake",
    "make",
    "c_compiler_stub",
    "cxx_compiler_stub",
    "cuda_compiler_stub",
    "go_compiler_stub 1.20",
    "go-licenses",
    "git",
    "cmake",
    "make",
    "c_compiler_stub",
    "cxx_compiler_stub",
    "cuda_compiler_stub",
    "go_compiler_stub 1.20",
    "go-licenses",
    "git",
    "cmake",
    "make",
    "cuda-cudart-dev",
    "libcublas-dev",
    "c_compiler_stub",
    "cxx_compiler_stub",
    "go_compiler_stub 1.20",
    "go-licenses",
    "git",
    "cmake",
    "make"
   ],
   "host": [
    "cuda-cudart-dev",
    "libcublas-dev"
   ],
   "run": [
    "cuda-version 11.2",
    "cuda-version 11.8",
    "cuda-version 12.0",
    "cuda-cudart"
   ]
  },
  "source": [
   {
    "folder": ".",
    "patches": [
     "0001-darwin_amd64.patch",
     "0001-darwin_arm64.patch",
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch"
    ],
    "sha256": "881d81d6a113f5361fc1648ee3f07f596b96a25ff9c9e6b243c2386adb8a0b26",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.11.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "sha256": "9c127ec8a6c54e7c03e2a246a41382ce7df7c4e46543bc7fec685600d6e2e6d9",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1412.tar.gz"
   },
   {
    "folder": ".",
    "patches": [
     "0001-darwin_amd64.patch",
     "0001-darwin_arm64.patch",
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch"
    ],
    "sha256": "881d81d6a113f5361fc1648ee3f07f596b96a25ff9c9e6b243c2386adb8a0b26",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.11.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "sha256": "9c127ec8a6c54e7c03e2a246a41382ce7df7c4e46543bc7fec685600d6e2e6d9",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1412.tar.gz"
   },
   {
    "folder": ".",
    "patches": [
     "0001-darwin_amd64.patch",
     "0001-darwin_arm64.patch",
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch"
    ],
    "sha256": "881d81d6a113f5361fc1648ee3f07f596b96a25ff9c9e6b243c2386adb8a0b26",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.11.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "sha256": "9c127ec8a6c54e7c03e2a246a41382ce7df7c4e46543bc7fec685600d6e2e6d9",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1412.tar.gz"
   },
   {
    "folder": ".",
    "patches": [
     "0001-darwin_amd64.patch",
     "0001-darwin_arm64.patch",
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch"
    ],
    "sha256": "881d81d6a113f5361fc1648ee3f07f596b96a25ff9c9e6b243c2386adb8a0b26",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.11.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "sha256": "9c127ec8a6c54e7c03e2a246a41382ce7df7c4e46543bc7fec685600d6e2e6d9",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1412.tar.gz"
   }
  ],
  "test": {
   "commands": [
    "ollama --version",
    "ollama --help",
    "ollama --version",
    "ollama --help",
    "ollama --version",
    "ollama --help",
    "ollama --version",
    "ollama --help"
   ]
  }
 },
 "linux_64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cmake",
    "cuda-cudart-dev",
    "cuda_compiler_stub",
    "cxx_compiler_stub",
    "git",
    "go-licenses",
    "go_compiler_stub",
    "libcublas-dev",
    "make"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "cuda-cudart-dev",
    "libcublas-dev"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "cuda-cudart",
    "cuda-version"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "meta_yaml": {
  "about": {
   "dev_url": "https://github.com/jmorganca/ollama",
   "home": "https://ollama.ai",
   "license": "MIT",
   "license_family": "MIT",
   "license_file": [
    "LICENSE",
    "licenses/",
    "LICENSE",
    "licenses/",
    "LICENSE",
    "licenses/",
    "LICENSE",
    "licenses/",
    "LICENSE",
    "licenses/",
    "LICENSE",
    "licenses/",
    "LICENSE",
    "licenses/"
   ],
   "summary": "Get up and running with Llama 2 and other large language models locally"
  },
  "build": {
   "ignore_run_exports_from": null,
   "number": "4",
   "script": [
    "git config --system user.email \"conda-forge@numfocus.org\"",
    "git config --system user.name \"Conda Forge\"",
    "git config --global init.defaultBranch main",
    "pushd llm/llama.cpp/ggml\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "pushd llm/llama.cpp/gguf\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "export GOFLAGS=\"'-ldflags=-X=github.com/jmorganca/ollama/version.Version=0.1.11 -X=github.com/jmorganca/ollama/server.mode=release'\"",
    "go generate ./...",
    "go install .",
    "go-licenses save --save_path licenses ./...",
    "git config --system user.email \"conda-forge@numfocus.org\"",
    "git config --system user.name \"Conda Forge\"",
    "git config --global init.defaultBranch main",
    "pushd llm/llama.cpp/ggml\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "pushd llm/llama.cpp/gguf\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "export GOFLAGS=\"'-ldflags=-X=github.com/jmorganca/ollama/version.Version=0.1.11 -X=github.com/jmorganca/ollama/server.mode=release'\"",
    "go generate ./...",
    "go install .",
    "go-licenses save --save_path licenses ./...",
    "git config --system user.email \"conda-forge@numfocus.org\"",
    "git config --system user.name \"Conda Forge\"",
    "git config --global init.defaultBranch main",
    "pushd llm/llama.cpp/ggml\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "pushd llm/llama.cpp/gguf\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "export GOFLAGS=\"'-ldflags=-X=github.com/jmorganca/ollama/version.Version=0.1.11 -X=github.com/jmorganca/ollama/server.mode=release'\"",
    "go generate ./...",
    "go install .",
    "go-licenses save --save_path licenses ./...",
    "git config --system user.email \"conda-forge@numfocus.org\"",
    "git config --system user.name \"Conda Forge\"",
    "git config --global init.defaultBranch main",
    "pushd llm/llama.cpp/ggml\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "pushd llm/llama.cpp/gguf\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "export GOFLAGS=\"'-ldflags=-X=github.com/jmorganca/ollama/version.Version=0.1.11 -X=github.com/jmorganca/ollama/server.mode=release'\"",
    "go generate ./...",
    "go install .",
    "go-licenses save --save_path licenses ./...",
    "git config --system user.email \"conda-forge@numfocus.org\"",
    "git config --system user.name \"Conda Forge\"",
    "git config --global init.defaultBranch main",
    "pushd llm/llama.cpp/ggml\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "pushd llm/llama.cpp/gguf\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "export GOFLAGS=\"'-ldflags=-X=github.com/jmorganca/ollama/version.Version=0.1.11 -X=github.com/jmorganca/ollama/server.mode=release'\"",
    "go generate ./...",
    "go install .",
    "go-licenses save --save_path licenses ./...",
    "git config --system user.email \"conda-forge@numfocus.org\"",
    "git config --system user.name \"Conda Forge\"",
    "git config --global init.defaultBranch main",
    "pushd llm/llama.cpp/ggml\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "pushd llm/llama.cpp/gguf\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "export GOFLAGS=\"'-ldflags=-X=github.com/jmorganca/ollama/version.Version=0.1.11 -X=github.com/jmorganca/ollama/server.mode=release'\"",
    "go generate ./...",
    "go install .",
    "go-licenses save --save_path licenses ./...",
    "git config --system user.email \"conda-forge@numfocus.org\"",
    "git config --system user.name \"Conda Forge\"",
    "git config --global init.defaultBranch main",
    "pushd llm/llama.cpp/ggml\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "pushd llm/llama.cpp/gguf\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "export GOFLAGS=\"'-ldflags=-X=github.com/jmorganca/ollama/version.Version=0.1.11 -X=github.com/jmorganca/ollama/server.mode=release'\"",
    "go generate ./...",
    "go install .",
    "go-licenses save --save_path licenses ./..."
   ],
   "string": "cpu_h1234567_4"
  },
  "extra": {
   "recipe-maintainers": [
    "sodre",
    "sodre",
    "sodre",
    "sodre",
    "sodre",
    "sodre",
    "sodre"
   ]
  },
  "package": {
   "name": "ollama",
   "version": "0.1.11"
  },
  "requirements": {
   "build": [
    "c_compiler_stub",
    "cxx_compiler_stub",
    "cuda_compiler_stub",
    "go_compiler_stub 1.20",
    "go-licenses",
    "git",
    "cmake",
    "make",
    "c_compiler_stub",
    "cxx_compiler_stub",
    "cuda_compiler_stub",
    "go_compiler_stub 1.20",
    "go-licenses",
    "git",
    "cmake",
    "make",
    "c_compiler_stub",
    "cxx_compiler_stub",
    "cuda_compiler_stub",
    "go_compiler_stub 1.20",
    "go-licenses",
    "git",
    "cmake",
    "make",
    "cuda-cudart-dev",
    "libcublas-dev",
    "c_compiler_stub",
    "cxx_compiler_stub",
    "go_compiler_stub 1.20",
    "go-licenses",
    "git",
    "cmake",
    "make",
    "c_compiler_stub",
    "cxx_compiler_stub",
    "go_compiler_stub 1.20",
    "go-licenses",
    "git",
    "cmake",
    "make",
    "c_compiler_stub",
    "cxx_compiler_stub",
    "go_compiler_stub 1.20",
    "go-licenses",
    "git",
    "cmake",
    "make",
    "c_compiler_stub",
    "cxx_compiler_stub",
    "go_compiler_stub 1.20",
    "go-licenses",
    "git",
    "cmake"
   ],
   "host": [
    "cuda-cudart-dev",
    "libcublas-dev"
   ],
   "run": [
    "cuda-version 11.2",
    "cuda-version 11.8",
    "cuda-version 12.0",
    "cuda-cudart"
   ]
  },
  "source": [
   {
    "folder": ".",
    "patches": [
     "0001-darwin_amd64.patch",
     "0001-darwin_arm64.patch",
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch"
    ],
    "sha256": "881d81d6a113f5361fc1648ee3f07f596b96a25ff9c9e6b243c2386adb8a0b26",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.11.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "sha256": "9c127ec8a6c54e7c03e2a246a41382ce7df7c4e46543bc7fec685600d6e2e6d9",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1412.tar.gz"
   },
   {
    "folder": ".",
    "patches": [
     "0001-darwin_amd64.patch",
     "0001-darwin_arm64.patch",
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch"
    ],
    "sha256": "881d81d6a113f5361fc1648ee3f07f596b96a25ff9c9e6b243c2386adb8a0b26",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.11.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "sha256": "9c127ec8a6c54e7c03e2a246a41382ce7df7c4e46543bc7fec685600d6e2e6d9",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1412.tar.gz"
   },
   {
    "folder": ".",
    "patches": [
     "0001-darwin_amd64.patch",
     "0001-darwin_arm64.patch",
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch"
    ],
    "sha256": "881d81d6a113f5361fc1648ee3f07f596b96a25ff9c9e6b243c2386adb8a0b26",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.11.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "sha256": "9c127ec8a6c54e7c03e2a246a41382ce7df7c4e46543bc7fec685600d6e2e6d9",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1412.tar.gz"
   },
   {
    "folder": ".",
    "patches": [
     "0001-darwin_amd64.patch",
     "0001-darwin_arm64.patch",
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch"
    ],
    "sha256": "881d81d6a113f5361fc1648ee3f07f596b96a25ff9c9e6b243c2386adb8a0b26",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.11.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "sha256": "9c127ec8a6c54e7c03e2a246a41382ce7df7c4e46543bc7fec685600d6e2e6d9",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1412.tar.gz"
   },
   {
    "folder": ".",
    "patches": [
     "0001-darwin_amd64.patch",
     "0001-darwin_arm64.patch",
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch"
    ],
    "sha256": "881d81d6a113f5361fc1648ee3f07f596b96a25ff9c9e6b243c2386adb8a0b26",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.11.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "sha256": "9c127ec8a6c54e7c03e2a246a41382ce7df7c4e46543bc7fec685600d6e2e6d9",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1412.tar.gz"
   },
   {
    "folder": ".",
    "patches": [
     "0001-darwin_amd64.patch",
     "0001-darwin_arm64.patch",
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch"
    ],
    "sha256": "881d81d6a113f5361fc1648ee3f07f596b96a25ff9c9e6b243c2386adb8a0b26",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.11.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "sha256": "9c127ec8a6c54e7c03e2a246a41382ce7df7c4e46543bc7fec685600d6e2e6d9",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1412.tar.gz"
   },
   {
    "folder": ".",
    "patches": [
     "0001-darwin_amd64.patch",
     "0001-darwin_arm64.patch",
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch"
    ],
    "sha256": "881d81d6a113f5361fc1648ee3f07f596b96a25ff9c9e6b243c2386adb8a0b26",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.11.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "sha256": "9c127ec8a6c54e7c03e2a246a41382ce7df7c4e46543bc7fec685600d6e2e6d9",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1412.tar.gz"
   }
  ],
  "test": {
   "commands": [
    "ollama --version",
    "ollama --help",
    "ollama --version",
    "ollama --help",
    "ollama --version",
    "ollama --help",
    "ollama --version",
    "ollama --help",
    "ollama --version",
    "ollama --help",
    "ollama --version",
    "ollama --help",
    "ollama --version",
    "ollama --help"
   ]
  }
 },
 "name": "ollama",
 "osx_64_meta_yaml": {
  "about": {
   "dev_url": "https://github.com/jmorganca/ollama",
   "home": "https://ollama.ai",
   "license": "MIT",
   "license_family": "MIT",
   "license_file": [
    "LICENSE",
    "licenses/"
   ],
   "summary": "Get up and running with Llama 2 and other large language models locally"
  },
  "build": {
   "ignore_run_exports_from": [
    "cxx_compiler_stub"
   ],
   "number": "4",
   "script": [
    "git config --system user.email \"conda-forge@numfocus.org\"",
    "git config --system user.name \"Conda Forge\"",
    "git config --global init.defaultBranch main",
    "pushd llm/llama.cpp/ggml\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "pushd llm/llama.cpp/gguf\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "export GOFLAGS=\"'-ldflags=-X=github.com/jmorganca/ollama/version.Version=0.1.11 -X=github.com/jmorganca/ollama/server.mode=release'\"",
    "go generate ./...",
    "go install .",
    "go-licenses save --save_path licenses ./..."
   ],
   "string": "cpu_h1234567_4"
  },
  "extra": {
   "recipe-maintainers": [
    "sodre"
   ]
  },
  "package": {
   "name": "ollama",
   "version": "0.1.11"
  },
  "requirements": {
   "build": [
    "c_compiler_stub",
    "cxx_compiler_stub",
    "go_compiler_stub 1.20",
    "go-licenses",
    "git",
    "cmake",
    "make"
   ],
   "host": [],
   "run": []
  },
  "source": [
   {
    "folder": ".",
    "patches": [
     "0001-darwin_amd64.patch",
     "0001-darwin_arm64.patch",
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch"
    ],
    "sha256": "881d81d6a113f5361fc1648ee3f07f596b96a25ff9c9e6b243c2386adb8a0b26",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.11.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "sha256": "9c127ec8a6c54e7c03e2a246a41382ce7df7c4e46543bc7fec685600d6e2e6d9",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1412.tar.gz"
   }
  ],
  "test": {
   "commands": [
    "ollama --version",
    "ollama --help"
   ]
  }
 },
 "osx_64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cmake",
    "cxx_compiler_stub",
    "git",
    "go-licenses",
    "go_compiler_stub",
    "make"
   ]
  },
  "host": {
   "__set__": true,
   "elements": []
  },
  "run": {
   "__set__": true,
   "elements": []
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "osx_arm64_meta_yaml": {
  "about": {
   "dev_url": "https://github.com/jmorganca/ollama",
   "home": "https://ollama.ai",
   "license": "MIT",
   "license_family": "MIT",
   "license_file": [
    "LICENSE",
    "licenses/"
   ],
   "summary": "Get up and running with Llama 2 and other large language models locally"
  },
  "build": {
   "ignore_run_exports_from": [
    "cxx_compiler_stub"
   ],
   "number": "4",
   "script": [
    "git config --system user.email \"conda-forge@numfocus.org\"",
    "git config --system user.name \"Conda Forge\"",
    "git config --global init.defaultBranch main",
    "pushd llm/llama.cpp/ggml\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "pushd llm/llama.cpp/gguf\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "export GOFLAGS=\"'-ldflags=-X=github.com/jmorganca/ollama/version.Version=0.1.11 -X=github.com/jmorganca/ollama/server.mode=release'\"",
    "go generate ./...",
    "go install .",
    "go-licenses save --save_path licenses ./..."
   ],
   "string": "cpu_h1234567_4"
  },
  "extra": {
   "recipe-maintainers": [
    "sodre"
   ]
  },
  "package": {
   "name": "ollama",
   "version": "0.1.11"
  },
  "requirements": {
   "build": [
    "c_compiler_stub",
    "cxx_compiler_stub",
    "go_compiler_stub 1.20",
    "go-licenses",
    "git",
    "cmake",
    "make"
   ],
   "host": [],
   "run": []
  },
  "source": [
   {
    "folder": ".",
    "patches": [
     "0001-darwin_amd64.patch",
     "0001-darwin_arm64.patch",
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch"
    ],
    "sha256": "881d81d6a113f5361fc1648ee3f07f596b96a25ff9c9e6b243c2386adb8a0b26",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.11.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "sha256": "9c127ec8a6c54e7c03e2a246a41382ce7df7c4e46543bc7fec685600d6e2e6d9",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1412.tar.gz"
   }
  ],
  "test": {
   "commands": [
    "ollama --version",
    "ollama --help"
   ]
  }
 },
 "osx_arm64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cmake",
    "cxx_compiler_stub",
    "git",
    "go-licenses",
    "go_compiler_stub",
    "make"
   ]
  },
  "host": {
   "__set__": true,
   "elements": []
  },
  "run": {
   "__set__": true,
   "elements": []
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "outputs_names": {
  "__set__": true,
  "elements": [
   "ollama"
  ]
 },
 "parsing_error": false,
 "platforms": [
  "linux_64",
  "osx_64",
  "osx_arm64",
  "win_64"
 ],
 "pr_info": {
  "__lazy_json__": "pr_info/ollama.json"
 },
 "raw_meta_yaml": "{% set name = \"ollama\" %}\n{% set goname = \"github.com/jmorganca/ollama\" %}\n# DO NOT AUTO MERGE WITHOUT VERIFYING THE GIT_REVISIONS OF ggml AND gguf\n{% set version = \"0.1.11\" %}\n{% set ggml_version = \"master-9e232f0\" %}\n{% set ggml_sha256 = \"e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef\" %}\n{% set gguf_version = \"b1412\" %}\n{% set gguf_sha256 = \"9c127ec8a6c54e7c03e2a246a41382ce7df7c4e46543bc7fec685600d6e2e6d9\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  - url: https://{{ goname }}/archive/v{{ version }}.tar.gz\n    sha256: 881d81d6a113f5361fc1648ee3f07f596b96a25ff9c9e6b243c2386adb8a0b26\n    folder: .\n    patches:\n      # Use the same build options from llama.cpp-feedstock\n      - 0001-darwin_amd64.patch\n      - 0001-darwin_arm64.patch\n      - 0001-remove-submodule.patch\n      - 0001-linux_all-do-not-copy-cuda.patch\n  - url: https://github.com/ggerganov/llama.cpp/archive/{{ ggml_version }}.tar.gz\n    folder: llm/llama.cpp/ggml\n    sha256: {{ ggml_sha256 }}\n  - url: https://github.com/ggerganov/llama.cpp/archive/{{ gguf_version }}.tar.gz\n    folder: llm/llama.cpp/gguf\n    sha256: {{ gguf_sha256 }}\n\nbuild:\n  number: 4\n  skip: True  # [win and cuda_compiler_version != \"None\"]\n  string: cuda{{ cuda_compiler_version | replace('.', '') }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != \"None\"]\n  string: mps_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [osx and arm64]\n  string: cpu_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [(osx and x86_64) or cuda_compiler_version == \"None\"]\n  script:\n    - git config --system user.email \"conda-forge@numfocus.org\"\n    - git config --system user.name \"Conda Forge\"\n    - git config --global init.defaultBranch main\n    {% for framework in [\"ggml\", \"gguf\"] %}\n    - |\n      pushd llm/llama.cpp/{{ framework }}\n      git init\n      git add .\n      git commit -m \"conda-forge build\"\n      popd\n    {% endfor %}\n    - export GOFLAGS=\"'-ldflags=-X=github.com/jmorganca/ollama/version.Version={{ version }} -X=github.com/jmorganca/ollama/server.mode=release'\"\n    - go generate ./...\n    - go install .                                                                                                            # [build_platform == target_platform]\n    # TODO: This is due to a bug in our go-lang patch \n    #       Error message is go install can't write to GOBIN when cross compiling\n    - unset CONDA_GO_COMPILER; GOPATH=$SRC_DIR/gopath go install .; mkdir -p $PREFIX/bin; cp gopath/bin/*/ollama $PREFIX/bin  # [build_platform != target_platform]\n    - go-licenses save --save_path licenses ./...\n\n  ignore_run_exports_from:\n    # llama.cpp server is staticially linked on osx\n    - {{ compiler('cxx') }}  # [osx]\n\nrequirements:\n  build:\n    - {{ compiler('c') }}\n    - {{ compiler('cxx') }}\n    - {{ compiler('cuda') }}                    # [cuda_compiler_version not in (undefined, \"None\")]\n    - {{ compiler('go') }} 1.20\n    - go-licenses\n\n    - git\n    - cmake\n    - make                                      # [unix]\n\n    # Tool can't find cudart/cublas in the host-environment\n    - cuda-cudart-dev                           # [(cuda_compiler_version or \"\").startswith(\"12\")]\n    - libcublas-dev                             # [(cuda_compiler_version or \"\").startswith(\"12\")]\n  host:\n    - cuda-cudart-dev                           # [(cuda_compiler_version or \"\").startswith(\"12\")]\n    - libcublas-dev                             # [(cuda_compiler_version or \"\").startswith(\"12\")]\n  run:\n    - cuda-version {{ cuda_compiler_version }}  # [cuda_compiler_version not in (undefined, \"None\")]\n    - cuda-cudart                               # [(cuda_compiler_version or \"\").startswith(\"12\")]\n\ntest:\n  commands:\n    - ollama --version\n    - ollama --help\n\nabout:\n  home: https://ollama.ai\n  summary: Get up and running with Llama 2 and other large language models locally\n  license: MIT\n  license_family: MIT\n  license_file:\n    - LICENSE\n    - licenses/\n  dev_url: https://{{ goname }}\n\nextra:\n  recipe-maintainers:\n    - sodre\n",
 "req": {
  "__set__": true,
  "elements": [
   "c_compiler_stub",
   "cmake",
   "cuda-cudart",
   "cuda-cudart-dev",
   "cuda-version",
   "cuda_compiler_stub",
   "cxx_compiler_stub",
   "git",
   "go-licenses",
   "go_compiler_stub",
   "libcublas-dev",
   "make"
  ]
 },
 "requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cmake",
    "cuda-cudart-dev",
    "cuda_compiler_stub",
    "cxx_compiler_stub",
    "git",
    "go-licenses",
    "go_compiler_stub",
    "libcublas-dev",
    "make"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cuda-cudart-dev",
    "cuda_compiler_stub",
    "cxx_compiler_stub",
    "libcublas-dev"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cuda-cudart",
    "cuda-version",
    "cuda_compiler_stub",
    "cxx_compiler_stub"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "strong_exports": false,
 "total_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cmake",
    "cuda-cudart-dev",
    "cuda_compiler_stub",
    "cxx_compiler_stub",
    "git",
    "go-licenses",
    "go_compiler_stub 1.20",
    "libcublas-dev",
    "make"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "cuda-cudart-dev",
    "libcublas-dev"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "cuda-cudart",
    "cuda-version 11.2",
    "cuda-version 11.8",
    "cuda-version 12.0"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "url": "https://github.com/jmorganca/ollama/archive/v0.1.11.tar.gz",
 "version": "0.1.11",
 "version_pr_info": {
  "__lazy_json__": "version_pr_info/ollama.json"
 },
 "win_64_meta_yaml": {
  "about": {
   "dev_url": "https://github.com/jmorganca/ollama",
   "home": "https://ollama.ai",
   "license": "MIT",
   "license_family": "MIT",
   "license_file": [
    "LICENSE",
    "licenses/"
   ],
   "summary": "Get up and running with Llama 2 and other large language models locally"
  },
  "build": {
   "ignore_run_exports_from": null,
   "number": "4",
   "script": [
    "git config --system user.email \"conda-forge@numfocus.org\"",
    "git config --system user.name \"Conda Forge\"",
    "git config --global init.defaultBranch main",
    "pushd llm/llama.cpp/ggml\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "pushd llm/llama.cpp/gguf\ngit init\ngit add .\ngit commit -m \"conda-forge build\"\npopd\n",
    "export GOFLAGS=\"'-ldflags=-X=github.com/jmorganca/ollama/version.Version=0.1.11 -X=github.com/jmorganca/ollama/server.mode=release'\"",
    "go generate ./...",
    "go install .",
    "go-licenses save --save_path licenses ./..."
   ],
   "string": "cpu_h1234567_4"
  },
  "extra": {
   "recipe-maintainers": [
    "sodre"
   ]
  },
  "package": {
   "name": "ollama",
   "version": "0.1.11"
  },
  "requirements": {
   "build": [
    "c_compiler_stub",
    "cxx_compiler_stub",
    "go_compiler_stub 1.20",
    "go-licenses",
    "git",
    "cmake"
   ],
   "host": [],
   "run": []
  },
  "source": [
   {
    "folder": ".",
    "patches": [
     "0001-darwin_amd64.patch",
     "0001-darwin_arm64.patch",
     "0001-remove-submodule.patch",
     "0001-linux_all-do-not-copy-cuda.patch"
    ],
    "sha256": "881d81d6a113f5361fc1648ee3f07f596b96a25ff9c9e6b243c2386adb8a0b26",
    "url": "https://github.com/jmorganca/ollama/archive/v0.1.11.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/ggml",
    "sha256": "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef",
    "url": "https://github.com/ggerganov/llama.cpp/archive/master-9e232f0.tar.gz"
   },
   {
    "folder": "llm/llama.cpp/gguf",
    "sha256": "9c127ec8a6c54e7c03e2a246a41382ce7df7c4e46543bc7fec685600d6e2e6d9",
    "url": "https://github.com/ggerganov/llama.cpp/archive/b1412.tar.gz"
   }
  ],
  "test": {
   "commands": [
    "ollama --version",
    "ollama --help"
   ]
  }
 },
 "win_64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cmake",
    "cxx_compiler_stub",
    "git",
    "go-licenses",
    "go_compiler_stub"
   ]
  },
  "host": {
   "__set__": true,
   "elements": []
  },
  "run": {
   "__set__": true,
   "elements": []
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 }
}